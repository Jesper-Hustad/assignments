{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) ineær regresjon i 3 dimensjoner:\r\n",
    "<!-- Based on [linear-2d](https://gitlab.com/ntnu-tdat3025/regression/linear-2d) by Ole Christian Eidheim. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import time\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from matplotlib import cm\r\n",
    "from mpl_toolkits.mplot3d import axes3d, art3d\r\n",
    "from matplotlib.animation import FuncAnimation\r\n",
    "%matplotlib qt\r\n",
    "\r\n",
    "\r\n",
    "global x_train\r\n",
    "global y_train\r\n",
    "global model\r\n",
    "global ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train[0:10] = tensor([[ 604.0000,   84.8655],\n",
      "        [ 964.0000,   92.8221],\n",
      "        [1640.0000,   98.5218],\n",
      "        [ 642.0000,   85.6332],\n",
      "        [ 467.0000,   75.2944],\n",
      "        [ 447.0000,   79.7825],\n",
      "        [1450.0000,   99.4479],\n",
      "        [1472.0000,  105.3180],\n",
      "        [1661.0000,  116.2802],\n",
      "        [1776.0000,  107.2823]]) \n",
      "y_train[0:10] = tensor([[13.0302],\n",
      "        [14.7191],\n",
      "        [21.0195],\n",
      "        [12.7910],\n",
      "        [10.5395],\n",
      "        [ 9.3395],\n",
      "        [12.4751],\n",
      "        [12.1663],\n",
      "        [20.8239],\n",
      "        [16.3704]])\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('day_length_weight.csv')\r\n",
    "\r\n",
    "day = train.iloc[0::,0]\r\n",
    "day_list = day.values.tolist()\r\n",
    "x1_train = torch.tensor(day_list).reshape(-1, 1)\r\n",
    "\r\n",
    "length = train.iloc[0::,1]\r\n",
    "length_list = length.values.tolist()\r\n",
    "x2_train = torch.tensor(length_list).reshape(-1, 1)\r\n",
    "\r\n",
    "weight = train.iloc[0::,2]\r\n",
    "weight_list = weight.values.tolist()\r\n",
    "y_train = torch.tensor(weight_list).reshape(-1, 1)\r\n",
    "\r\n",
    "x_train = torch.cat((x1_train, x2_train),1).float()\r\n",
    "\r\n",
    "print(f\"{x_train[0:10] = }\",f\"\\n{y_train[0:10] = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Linear Regression Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel:\r\n",
    "    def __init__(self):\r\n",
    "        # Model variables\r\n",
    "        self.W = torch.tensor([[-0.2], [0.53]], requires_grad=True)  # requires_grad enables calculation of gradients\r\n",
    "        self.b = torch.tensor([[3.1]], requires_grad=True)\r\n",
    "\r\n",
    "    # Predictor\r\n",
    "    def f(self, x):\r\n",
    "        return x @ self.W + self.b  # @ corresponds to matrix multiplication\r\n",
    "\r\n",
    "    # Uses Mean Squared Error\r\n",
    "    def loss(self, x, y):\r\n",
    "        return torch.nn.functional.mse_loss(self.f(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize with stochastic gradient descent (SGD)\r\n",
    "PyTorch's built in optimizer does a lot of the work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [-0.20000000298023224, 0.5299999713897705], b = 3.0999999046325684, loss = 3.636127233505249\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegressionModel()\r\n",
    "\r\n",
    "# set variables\r\n",
    "scale = 10**(-2)\r\n",
    "epoch_count = 1\r\n",
    "step_length = 0.008\r\n",
    "\r\n",
    "# downscale\r\n",
    "x_train = x_train * scale\r\n",
    "y_train = y_train * scale\r\n",
    "\r\n",
    "# Optimize: adjust W and b to minimize loss using stochastic gradient descent\r\n",
    "optimizer = torch.optim.SGD([model.W, model.b], step_length)\r\n",
    "\r\n",
    "for epoch in range(epoch_count):\r\n",
    "    \r\n",
    "    model.loss(x_train, y_train).backward()  # Compute loss gradients\r\n",
    "\r\n",
    "    optimizer.step()  # Perform optimization by adjusting W and b,\r\n",
    "\r\n",
    "    optimizer.zero_grad()  # Clear gradients for next step\r\n",
    "\r\n",
    "def run_epoch(plot, epo):\r\n",
    "    model.loss(x_train, y_train).backward()  # Compute loss gradients\r\n",
    "\r\n",
    "    optimizer.step()  # Perform optimization by adjusting W and b,\r\n",
    "\r\n",
    "    optimizer.zero_grad()  # Clear gradients for next step\r\n",
    "    plot.set_title(\"\\nW = %s\\n b = %s\\n loss = %s\\n epoch = %s\" % ([round(model.W[0].item(),4), round(model.W[1].item(),4)] ,round(model.b.item(),4), round(model.loss(x_train, y_train).item(),4), epo-100))\r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure\r\n",
    "fig = plt.figure()\r\n",
    "\r\n",
    "# Add an axes\r\n",
    "ax = fig.add_subplot(111,projection='3d')\r\n",
    "\r\n",
    "def animate(i):\r\n",
    "\r\n",
    "    fig.clear()\r\n",
    "\r\n",
    "    ax = fig.add_subplot(111,projection='3d')\r\n",
    "\r\n",
    "    run_epoch(ax, i)\r\n",
    "\r\n",
    "    ax.view_init(20, 50 + ((i/5) % 360))\r\n",
    "\r\n",
    "    # max min values for gird\r\n",
    "    x = torch.stack([torch.min(x_train, 0).values, torch.max(x_train, 0).values])\r\n",
    "\r\n",
    "    # setup grid vars\r\n",
    "    x1_grid, x2_grid = np.meshgrid(np.linspace(x[0,0], x[1,0], 10), np.linspace(x[0,1], x[1,1], 10))\r\n",
    "    y_grid = np.empty([10, 10])\r\n",
    "\r\n",
    "\r\n",
    "    # set grid values using model.f()\r\n",
    "    for i in range(0, x1_grid.shape[0]):\r\n",
    "        for j in range(0, x1_grid.shape[1]):\r\n",
    "            \r\n",
    "            # Xᵢ\r\n",
    "            x = torch.tensor( [[ x1_grid[i, j], x2_grid[i, j] ]] ).float()\r\n",
    "            \r\n",
    "            # yᵢ = f(xᵢ)\r\n",
    "            y_grid[i, j] = model.f(x)\r\n",
    "\r\n",
    "    # plot wireframe\r\n",
    "    ax.plot_wireframe(x1_grid, x2_grid, y_grid, color='orange')\r\n",
    "\r\n",
    "    # and plot the points \r\n",
    "    ax.scatter(x_train[:,0],x_train[:,1],y_train,  color='blue')\r\n",
    "\r\n",
    "\r\n",
    "ani = FuncAnimation(plt.gcf(), animate, interval=1)\r\n",
    "\r\n",
    "plt.show()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = tensor([[-0.2211],\n",
      "        [ 0.5107]], requires_grad=True), b = tensor([[307.1173]], grad_fn=<DivBackward0>), loss = tensor(3.1739, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Print model variables and loss\r\n",
    "print(\"W = %s, b = %s, loss = %s\" % (model.W, model.b/scale, model.loss(x_train, y_train)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python396jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}